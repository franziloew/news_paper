---
title: "Press Releases"
subtitle: "Analysing press releases from german parties"
author: "Franziska Löw"
date: "`r format(Sys.Date())`"
output: 
  html_document:
    code_folding: hide
---

```{r include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

This is part of my current [paper](https://github.com/franziloew/news_paper) about political reporting in German online news. 

To measure the ideological content of several major online news services, I compare the topics discussed in these media with the press releases of the Bundestag parties using a [structural topic model](https://www.structuraltopicmodel.com/).

The following is an analysis of the content of the press releases scraped from the public websites of the political parties and political groups. A big part of this analysis is inspired from the work of Julia Silge and David Robinson ([Text Mining with R - A Tidy Approach](https://www.tidytextmining.com/)).

```{r include=FALSE}
library(tidyverse)
library(lubridate)

rm(list = ls())
```

## Load Data

### CDU

- Partei (https://www.cdu.de)
- Fraktion / Union (https://www.presseportal.de)

```{r eval=FALSE, include=FALSE}
# Partei
load("../data/pressReleases/cdu.Rda")
cdu.p <- cdu %>% mutate(type = "party") %>% select(-scrape_time, -source)

# Fraktion
cdu.f <- read.csv("../data/pressReleases/python/cdu.csv", stringsAsFactors=FALSE)
cdu.f <- cdu.f %>% mutate(type = "faction") %>% select(-link)

# combine both
cdu <- rbind(cdu.p,cdu.f) %>% 
  # date format
  mutate(date = as.Date(date, format="%d.%m.%Y")) %>% 
  
  # clean text
  mutate(text = gsub('Berlin','',body, ignore.case = TRUE, perl = TRUE),
         text = gsub('ots','',text, ignore.case = TRUE, perl = TRUE),
         text = gsub('Presse.*','', text, perl = TRUE, ignore.case = TRUE),
         text = gsub('Telefon.*','', text, perl = TRUE, ignore.case = TRUE),
         text = gsub('Fax.*','', text, perl = TRUE, ignore.case = TRUE),
         text = gsub('Internet.*','', text, perl = TRUE, ignore.case = TRUE),
         text = gsub('Email.*','', text, perl = TRUE, ignore.case = TRUE),
         title = gsub('(.+?):','',title, perl = T),
         title_text = paste(title, text),
         party = "CDU"
         ) %>%
  distinct(title, .keep_all = T) %>%
  select(title, title_text, party, type, date)

rm(cdu.f, cdu.p)
```

### SPD

- Partei (https://www.spd.de)
- Fraktion (https://www.spdfraktion.de)

```{r eval=FALSE, include=FALSE}
# Partei
load("../data/pressReleases/spd.Rda")
spd.p <- spd %>% mutate(type = "party",
                        date = as.Date(date, format="%d.%m.%Y")
                        ) %>% select(-scrape_time, -source)

# Fraktion
spd.f <- read.csv("../data/pressReleases/python/spd.csv", stringsAsFactors=FALSE)
spd.f <- spd.f %>% mutate(type = "faction",
                          date = as.Date(gsub('\\|.*','',date, perl = T), format = "%d.%m.%Y")
                          ) %>% select(-link) 

# combine both
spd <- rbind(spd.p,spd.f) %>%
  
  # clean text
  mutate(text = gsub('(.+?):','', body, perl = TRUE, ignore.case = TRUE),
         title = title,
         title_text = paste(title, text),
         party = "SPD"
         ) %>%
  distinct(title, .keep_all = T) %>%
  select(title, title_text, party, type, date)
  
rm(spd.f, spd.p)
```

### FDP

- Partei (https://www.fdp.de)
- Fraktion (https://www.fdpbt.de)

```{r eval=FALSE, include=FALSE}
fdp.p <- read.csv("../data/pressReleases/python/fdp.csv", stringsAsFactors=FALSE)

fdp.p <- fdp.p %>%
  mutate(
    date = as.Date(date, format = "%d.%m.%Y"),
    title = gsub('\n','',title, perl = T),
    type = "party") 

fdp.f <- read.csv("../data/pressReleases/python/fdpbt.csv", stringsAsFactors=FALSE)

fdp.f <- fdp.f %>% 
  mutate(
        date = as.Date(date, format="%d.%m.%Y"),
        title = gsub('\n','', title, perl = T),
        title = gsub('\t','', title, perl = T),
        type = "faction")

# combine both
fdp <- rbind(fdp.p,fdp.f) %>%
  
  # clean text
  mutate(title = gsub('(.+?):','', title, perl = TRUE, ignore.case = TRUE),
         title_text = paste(title, body),
         party = "FDP"
         ) %>%
  distinct(title, .keep_all = T) %>%
  select(title, title_text, party, type, date)
  
rm(fdp.f, fdp.p)
```

### B90 / Die Grünen

- Partei (https://www.gruene.de)
- Fraktion (https://www.gruene-bundestag.de/)

```{r eval=FALSE, include=FALSE}
# Partei 
load("../data/pressReleases/gruene.Rda")
gruene.p <- gruene %>% mutate(type = "party",
                              date = as.Date(date, format="%d.%m.%Y")
                              ) %>% select(-scrape_time, -source)

# Fraktion
gruene.f <- read.csv("../data/pressReleases/python/gruene.csv", stringsAsFactors=FALSE)
gruene.f <- gruene.f %>% mutate(type = "faction",
                                date = as.Date(date, format="%d.%m.%Y")) %>% select(-link, -party) 

# combine both
gruene <- rbind(gruene.p,gruene.f) %>%
  # clean text
  mutate(text = gsub('Die Fraktionspressestelle auf Twitter: @GruenSprecher','',body),
         title = title,
         title_text = paste(title, text),
         party = "B90/GRÜNE"
         ) %>%
  distinct(title, .keep_all = T) %>%
  select(title, title_text, party, type, date)

rm(gruene.f, gruene.p)
```

### DIE LINKE

- Partei (https://www.die-linke.de)
- Fraktion (https://www.die-linke.de/start/presse/aus-dem-bundestag/)

```{r eval=FALSE, include=FALSE}
# Partei 
load("../data/pressReleases/linke.Rda")
linke.p <- linke %>% mutate(type = "party",
                            date = as.Date(date, format="%d. %B %Y")
                            ) %>% select(-scrape_time, -source)

# Fraktion
linke.f <- read.csv("../data/pressReleases/python/linke.csv", stringsAsFactors=FALSE)
linke.f <- linke.f %>% mutate(type = "faction",
                              date = gsub("\n","", date, perl = T),
                              date = as.Date(date, format="%d. %b %Y")) %>% select(-link, -party) 

# combine both
linke <- rbind(linke.p,linke.f) %>%
  # clean text
  mutate(text = body,
         title = title,
         title_text = paste(title, text),
         party = "DIE LINKE"
         ) %>%
  distinct(title, .keep_all = T) %>%
  select(title, title_text, party, type, date)

rm(linke.f, linke.p)
```

### AfD

- Partei (https://www.afd.de)
- Fraktion (https://www.afdbundestag.de)

```{r eval=FALSE, include=FALSE}
load("../data/pressReleases/afd.Rda")
load("../data/pressReleases/afdf.Rda")

afd <- rbind(afd %>% mutate(type = "party"), 
             afd.f %>% mutate(source = "AfD", type = "faction")) %>%
  mutate( date = str_extract(body, "(?<=,\\s)(\\d{1,2}.\\s\\w{1,}\\s\\d{4})"),
          date = as.Date(date, format = "%d. %B %Y"),
          text = gsub('Berlin[^n\\.]*','',body, ignore.case = TRUE, perl = TRUE),
          text = gsub(".fusion-button[^\n]*",'',text, ignore.case = TRUE, perl = TRUE),
          title_text = paste(title, text),
          party = "AfD"
          ) %>%
  distinct(title, .keep_all = T) %>%
  select(title, title_text, party, type, date)

rm(afd.f)
```

## Clean Data

```{r eval=FALSE, include=FALSE}
filter <- paste("vorsitz","personalentscheidung","gremien","rufbereitschaft","erreichbarkeit", sep = "|")
  
pressReleases <- bind_rows(cdu, spd, afd, gruene, linke, fdp) %>%
  filter(date >= as.Date("2017-06-01")) %>%
  filter(date < as.Date("2018-03-01")) %>%
  mutate(
    author = type,
    type = "press",
    text_length = sapply(gregexpr("\\S+", title_text), length)) %>%
  
  mutate(
    filtered = ifelse(grepl(filter,title,ignore.case = T), TRUE, FALSE),
    filtered = ifelse(text_length < 100, TRUE, filtered),
    filtered = ifelse(text_length > 1500, TRUE, filtered),
    filtered = ifelse(grepl("Interview", title_text), TRUE, filtered),
    filtered = ifelse(grepl("Gastbeitrag", title_text), TRUE, filtered)
  )

ggplot(pressReleases, aes(party, fill=filtered)) +
  geom_bar() +
  labs(x= NULL, y = NULL, fill = "filtered ?")
```

```{r message=FALSE, warning=FALSE, include=FALSE}
pressReleases <- pressReleases %>% filter(filtered == FALSE) 
```

### Pre-process Text 

1. Remove... 

  - Interview words (eg. Frage:, Lindner:)
  
```{r}
pressReleases <- pressReleases %>%
  mutate(title_text = gsub("Lindner:","",title_text),
         title_text = gsub("Kubicki:","",title_text),
         title_text = gsub("Lambsdorff:","",title_text),
         title_text = gsub("Beer:","",title_text),
         title_text = gsub("Frage:","",title_text)
         )
```

  - punctuation, numbers, special characters
  - stopwords (frequently used words, that are not important for the analysis like "und", "ist", "in",...)
  
```{r eval=FALSE, include=FALSE}
pressReleases$text_cleaned <- gsub("[[:punct:]]", " ", pressReleases$title_text)
pressReleases$text_cleaned <- gsub("[[:cntrl:]]", " ", pressReleases$text_cleaned)
pressReleases$text_cleaned <- gsub("[[:digit:]]", " ", pressReleases$text_cleaned)
pressReleases$text_cleaned <- gsub("^[[:space:]]+", " ", pressReleases$text_cleaned)
pressReleases$text_cleaned <- gsub("[[:space:]]+$", " ", pressReleases$text_cleaned)
pressReleases$text_cleaned <- tolower(pressReleases$text_cleaned)

## Remove stopwords
# 1
german_stopwords_full <- read.table("dict/german_stopwords_full.txt", stringsAsFactors = F)
german_stopwords_full <- german_stopwords_full$V1

# 2
mystopwords <- c("januar","februar","märz","april","mai","juni","juli","august",
                 "september","oktober","november","dezember",
                 "montag","dienstag","mittwoch","donnerstag","freitag","samstag","sonntag",
                 "button","hierzu","erklärt","erklären","sprecher","sprecherin",
                 "fraktionsvorsitzende","bundestagsabgeordnete",
                 "stellvertretende","vorsitzende","stellvertretender","vorsitzender",
                 "fraktionsvorsitzender","bundestagsabgeordneter",
                 "drucken","bundestagsfraktion","fraktion",
                 "freie","demokraten","freien","demokraten"
                 )
stopwords <- c(german_stopwords_full, mystopwords)
stopwords <- unique(stopwords)

# 3
pressReleases$text_cleaned<- tm::removeWords(pressReleases$text_cleaned, stopwords)

## Stemming
stem_text<- function(text, language = "porter", mc.cores = 1) {
  # stem each word in a block of text
  stem_string <- function(str, language) {
    str <- strsplit(x = str, split = "\\s")
    str <- SnowballC::wordStem(unlist(str), language = language)
    str <- paste(str, collapse = " ")
    return(str)
  }
   
  # stem each text block in turn
  x <- parallel::mclapply(X = text, FUN = stem_string, language, mc.cores = mc.cores)
   
  # return stemed text blocks
  return(unlist(x))
}

pressReleases$text_cleaned1 <- stem_text(pressReleases$text_cleaned)
```

```{r eval=FALSE, include=FALSE}
save(pressReleases, file = "../output/pressReleases.Rda")

pressReleases %>%
  select(party, title_text) %>%
  write.csv(file = "../output/pressReleases.csv")
```

# Save to Postgres
```{r}
library(RPostgreSQL)

# Connect to postgres
pg = dbDriver("PostgreSQL")

pw <- {
  "Up627R&F6"
}

con = dbConnect(pg, user="Franzi", 
                password=pw, 
                host="news-paper.cildx1grqozu.eu-west-2.rds.amazonaws.com", 
                port=5432,
                dbname="postgres")

rm(pw) # removes the password

dbWriteTable(con, "press_releases", 
             value = pressReleases, overwrite = TRUE, row.names = FALSE)
```

## Inspect Data 
```{r include=FALSE}
library(tidyverse)
library(tidytext)
library(scales)
library(htmlTable)
library(ggthemes)
library(viridis)
library(xtable)
library(ggridges)
theme_set(theme_ridges())

rm(list = ls())
color <- "#b7b7b7"
color1 <- "#778899"
color2 <- "#808080"
color3 <- "#000000"
load("../output/pressReleases.Rda")

party_colors <- c("#009ee0", "#32302e","#ffed00","#46962b","#ec008c", "#E3000F")
```


```{r}
pressReleases %>%
  group_by(party, author) %>%
  tally() %>%
  ggplot(aes(reorder(party, n),n, fill = author)) +
  geom_col() +
  coord_flip() +
  theme_hc() +
  scale_fill_manual(values = c("faction" = color, "party" = color1),
                    breaks = c("faction","party"),
                    labels = c("Parliamentary group", "Party")
                    ) +
  labs(y = NULL, x = NULL, fill = NULL)

ggsave("../figs/press_releases.png", width = 6, height = 4)
```

```{r}
maxval <- 1450
dd <- pressReleases %>% filter(text_length > maxval) %>% 
  group_by(party) %>% 
  summarise(outlier_txt=paste(text_length ,collapse=", "))

pressReleases %>%
  #filter(text_length < maxval) %>%
  ggplot(aes(x=party, y=text_length)) +
  geom_boxplot() +
  theme_hc() +
  # geom_text(data=dd,aes(y=maxval,label= outlier_txt),
  #           size=3, vjust=.1, hjust=-0.1) +
  # geom_segment(data=dd,
  #              aes(y=maxval*0.95, yend=maxval, xend=5),
  #              color = "red",
  #              arrow = arrow(length = unit(0.1,"cm"))) +
  labs(x=NULL, y="# of words")

#ggsave("../figs/press_releases_textlength.png", width = 6, height = 4)
```

### Tokens

```{r}
tokens <- pressReleases %>% unnest_tokens(word, text_cleaned)

tokens.count <- tokens %>%
  count(party, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word,party,n)
```


```{r}
tokens.count %>% 
  arrange(desc(tf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(party) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(word, tf, fill = party)) +
  geom_col(show.legend = FALSE, fill = "darkslategray4", alpha = 0.9) +
  labs(x = NULL, y = "Term Frequency") +
  facet_wrap(~party, ncol = 3, scales = "free") +
  coord_flip()

ggsave("../figs/tokens.png", width = 11, height = 7)
```

Compare the word frequency for the different parties.

- an empty space at low frequency indicates less similarity between two parties. 

- if words in a two-sided panel are closer to the zero-slope line the two parties use more similar words.

```{r}
frequency <- tokens.count %>%
  group_by(party) %>%
  mutate(proportion = n/sum(n)) %>%
  select(party, word, proportion) %>%
  spread(party, proportion) 
```

#### CDU
```{r fig.height=8, fig.width=12}
frequency %>% 
  gather(party, proportion, -word, -CDU) %>%
  ggplot(aes(x = proportion, y = `CDU`, color = abs(`CDU` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~party, nrow = 2) +
  theme(legend.position="none") +
  labs(y = "CDU", x = NULL)

ggsave("../figs/word_freq_CDU.png", width = 15, height = 10)
```

#### SPD
```{r fig.height=8, fig.width=12}
frequency %>% 
  gather(party, proportion, -word, -SPD) %>%
  ggplot(aes(x = proportion, y = `SPD`, color = abs(`SPD` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~party, nrow = 2) +
  theme(legend.position="none") +
  labs(y = "SPD", x = NULL)

ggsave("../figs/word_freq_SPD.png", width = 15, height = 10)
```

#### FDP
```{r fig.height=8, fig.width=12}
frequency %>% 
  gather(party, proportion, -word, -FDP) %>%
  ggplot(aes(x = proportion, y = `FDP`, color = abs(`FDP` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~party, nrow = 2) +
  theme(legend.position="none") +
  labs(y = "FDP", x = NULL)

#ggsave("../figs/word_freq_FDP.png", width = 15, height = 10)
```

#### B90/GRÜNE
```{r fig.height=8, fig.width=12}
frequency %>% 
  gather(party, proportion, -word, -`B90/GRÜNE`) %>%
  ggplot(aes(x = proportion, y = `B90/GRÜNE`, color = abs(`B90/GRÜNE` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~party, nrow = 2) +
  theme(legend.position="none") +
  labs(y = "B90/GRÜNE", x = NULL)

#ggsave("../figs/word_freq_GRUENE.png", width = 15, height = 10)
```

#### DIE LINKE
```{r fig.height=8, fig.width=12}
frequency %>% 
  gather(party, proportion, -word, -`DIE LINKE`) %>%
  ggplot(aes(x = proportion, y = `DIE LINKE`, color = abs(`DIE LINKE` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~party, nrow = 2) +
  theme(legend.position="none") +
  labs(y = "DIE LINKE", x = NULL)

#ggsave("../figs/word_freq_LINKE.png", width = 15, height = 10)
```

#### AfD
```{r fig.height=8, fig.width=12}
frequency %>% 
  gather(party, proportion, -word, -`AfD`) %>%
  ggplot(aes(x = proportion, y = `AfD`, color = abs(`AfD` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~party, nrow = 2) +
  theme(legend.position="none") +
  labs(y = "AfD", x = NULL)

#ggsave("../figs/word_freq_AfD.png", width = 15, height = 10)
```

### TF-IDF

The statistic tf-idf (term frequency - inverse document frequency) is intended to measure how important a word is to a document in a collection (or corpus) of documents. 

The inverse document frequency for any given term is defined as 

$$
idf\text{(term)}=\frac{n_{\text{documents}}}{n_{\text{documents containing term}}}
$$

Terms with low tf-idf:

```{r}
tokens.count %>%
  arrange(tf_idf) 
```

A 0 idf (and thus tf-idf) indicate, that these terms appear in all six parties press-releases. 

The inverse document frequency (and thus tf-idf) is very low (0) for terms that occur in many (all) of the documents (all press releases of one party) in a collection (all press releases of one party); 

Terms with high tf-idf.

```{r}
tokens.count %>%
  arrange(desc(tf_idf))
```

```{r fig.height=8, fig.width=10}
tokens.count %>% 
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(party) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = party)) +
  geom_col(show.legend = FALSE, fill = "darkslategray4", alpha = 0.9) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~party, ncol = 3, scales = "free") +
  coord_flip()

#ggsave("../figs/tf-idf.png", width = 11, height = 6)
```

### N-Grams

Words can be considered not only as single units, but also as their relationship to each other. N-grams, for example, help to investigate which words tend to follow others immediately. To do this, we tokenize the text into successive sequences of words called n-grams. By seeing how often word X is followed by word Y, we can then build a model of the relationships between them.

#### Bigrams

```{r}
bigrams <- pressReleases %>% unnest_tokens(bigram, text_cleaned1, token="ngrams", n=2)

bigrams.count <- bigrams %>%
  count(party, bigram, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(bigram,party,n)
```

```{r fig.height=8, fig.width=10}
bigrams.count %>% 
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(party) %>% 
  top_n(15) %>% 
  arrange(desc(tf_idf)) %>%
  ungroup %>%
  ggplot(aes(reorder(bigram, tf_idf), tf_idf, fill = party)) +
  geom_col(show.legend = FALSE, fill = "darkslategray4", alpha = 0.9) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~party, ncol = 3, scales = "free") +
  coord_flip()

#ggsave("../figs/tf-idf_bigram.png", width = 11, height = 6)
```

#### Trigrams

```{r}
trigrams <- pressReleases %>% unnest_tokens(trigram, text_cleaned1, token="ngrams", n=3)

trigrams.count <- trigrams %>%
  count(party, trigram, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(trigram,party,n)
```

```{r fig.height=8, fig.width=10}
trigrams.count %>% 
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(trigram, levels = rev(unique(trigram)))) %>% 
  group_by(party) %>% 
  top_n(15) %>% 
  arrange(desc(tf_idf)) %>%
  ungroup %>%
  ggplot(aes(reorder(trigram, tf_idf), tf_idf, fill = party)) +
  geom_col(show.legend = FALSE, fill = "darkslategray4", alpha = 0.9) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~party, ncol = 3, scales = "free") +
  coord_flip()

#ggsave("../figs/tf-idf_trigram.png", width = 12, height = 6)
```
