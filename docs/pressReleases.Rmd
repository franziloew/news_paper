---
title: "Press Releases"
output: html_notebook
---

```{r}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


```{r message=FALSE, warning=FALSE}
library(tidyverse)
rm(list = ls())
```

```{r}
fdp <- read.csv("../scrapedata/fdp.csv", stringsAsFactors=FALSE)

# get the first sentence of the "gastbeitrag" releases
text <- unlist(strsplit(fdp$body, '\\:|\\.'))
ignore <- text[!grep(pattern = "Gastbeitrag", text, ignore.case = T)]

fdp <- fdp %>%
  filter(!grepl("interview",title,ignore.case = T)) %>%
  transmute(text = gsub(paste(ignore, sep = "|", collapse = "|"),"", body),
            date = as.Date(date, format = "%d.%m.%Y"),
            title = gsub('(.+?):','',title, perl = T),
            title_text = paste(title, text),
            source = party
         ) 
```

```{r}
linke <- read.csv("../scrapedata/linke.csv", stringsAsFactors=FALSE)

linke <- linke %>%
  transmute(text = body,
            title = title,
            title_text = paste(title, text),
            date = gsub("\n","",date, perl = T),
            date = as.Date(date, format = "%d. %B %Y"),
            source = party)
```

```{r}
gruene <- read.csv("../scrapedata/gruene.csv", stringsAsFactors=FALSE)

gruene <- gruene %>%
  transmute(text = gsub('Die Fraktionspressestelle auf Twitter: @GruenSprecher','',body),
            title = title,
            title_text = paste(title, text),
            date = as.Date(date, format = "%d.%m.%Y"),
            source = party
         )
```

```{r}
spd <- read.csv("../scrapedata/spd.csv", stringsAsFactors=FALSE)

spd <- spd %>%
  transmute(text = gsub('(.+?):','', body, perl = TRUE, ignore.case = TRUE),
            title = title,
            title_text = paste(title, text),
            date = as.Date(gsub('\\|.*','',date, perl = T), format = "%d.%m.%Y"),
            source = "spd"
         )
```

```{r}
cdu <- read.csv("../scrapedata/cdu.csv", stringsAsFactors=FALSE)

cdu <- cdu %>%
  transmute(text = gsub('Berlin','',body, ignore.case = TRUE, perl = TRUE),
         text = gsub('ots','',text, ignore.case = TRUE, perl = TRUE),
         text = gsub('Presse.*','', text, perl = TRUE, ignore.case = TRUE),
         text = gsub('Telefon.*','', text, perl = TRUE, ignore.case = TRUE),
         text = gsub('Fax.*','', text, perl = TRUE, ignore.case = TRUE),
         text = gsub('Internet.*','', text, perl = TRUE, ignore.case = TRUE),
         text = gsub('Email.*','', text, perl = TRUE, ignore.case = TRUE),
         title = gsub('(.+?):','',title, perl = T),
         title_text = paste(title, text),
         date = as.Date(gsub('\\-.*','',date, perl = T), format = "%d.%m.%Y"),
         source = "union"
         ) 
```


```{r}
afd <- read.csv("../scrapedata/afd.csv", stringsAsFactors=FALSE)

afd <- afd %>%
  filter(!grepl("interview",title,ignore.case = T)) %>%
  transmute(text = gsub('Berlin[^n\\.]*','',body, ignore.case = TRUE, perl = TRUE),
         text = gsub('Drucken','',text, ignore.case = TRUE, perl = TRUE),
         title = gsub('(.+?):','',title, perl = T),
         title_text = paste(title, text),
         source = "afd",
         date = gsub('Mrz',"März",date),
         date = as.Date(date, format = "%d%b %Y")
         ) 
```

```{r}
pressReleases <- bind_rows(cdu, spd, afd, gruene, linke, fdp) %>%
  filter(date >= as.Date("2017-06-01")) %>%
  mutate(type = "press")
```

```{r}
pressReleases %>%
  ggplot(aes(source, fill=source)) +
  geom_bar(show.legend = F) +
  ggthemes::theme_hc() +
  ggthemes::scale_fill_hc() +
  labs(y = NULL, x = NULL, title = "Number of press releases (June 2017 - March 2018)")
```

# Clean Data
```{r}
pressReleases$text_cleaned <- gsub("[[:punct:]]", " ", pressReleases$title_text)
pressReleases$text_cleaned <- gsub("[[:cntrl:]]", " ", pressReleases$text_cleaned)
pressReleases$text_cleaned <- gsub("[[:digit:]]", " ", pressReleases$text_cleaned)
pressReleases$text_cleaned <- gsub("^[[:space:]]+", " ", pressReleases$text_cleaned)
pressReleases$text_cleaned <- gsub("[[:space:]]+$", " ", pressReleases$text_cleaned)
pressReleases$text_cleaned <- tolower(pressReleases$text_cleaned)

## Remove stopwords
# 1
german_stopwords_full <- read.table("dict/german_stopwords_full.txt", stringsAsFactors = F)
german_stopwords_full <- german_stopwords_full$V1

# 2
mystopwords <- c("januar","feburar","märz","april","mai","juni","juli",
                 "august","september","oktober","november","dezember",
                 "linke","cdu","csu","union","spd","afd","grüne","fdp"
                 )
stopwords <- c(german_stopwords_full, mystopwords)
stopwords <- unique(stopwords)

# 3
pressReleases$text_cleaned<- tm::removeWords(pressReleases$text_cleaned, stopwords)

## Stemming
stem_text<- function(text, language = "porter", mc.cores = 1) {
  # stem each word in a block of text
  stem_string <- function(str, language) {
    str <- strsplit(x = str, split = "\\s")
    str <- SnowballC::wordStem(unlist(str), language = language)
    str <- paste(str, collapse = " ")
    return(str)
  }
   
  # stem each text block in turn
  x <- parallel::mclapply(X = text, FUN = stem_string, language, mc.cores = mc.cores)
   
  # return stemed text blocks
  return(unlist(x))
}

pressReleases$text_cleaned1 <- stem_text(pressReleases$text_cleaned)
```

```{r}
save(pressReleases, file = "../output/pressReleases.Rda")
```

```{r}
pressReleases %>%
  sample_n(1) %>%
  select(text_cleaned, text_cleaned1) %>%
  htmlTable::htmlTable()
```

# Inspect Data

```{r}
library(tidytext)

tokens <- pressReleases %>% unnest_tokens(word, text_cleaned)
bigrams <- pressReleases %>% unnest_tokens(bigrams, text_cleaned, token="ngrams", n=2)
```

```{r}
tokens2 <- tokens %>%
  count(party, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word,party,n)

tokens2 %>% 
    arrange(desc(tf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(party) %>% 
  top_n(10) %>% 
  ungroup %>%
  ggplot(aes(word, tf, fill = party)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~party, ncol = 2, scales = "free") +
  coord_flip()
```

```{r}
bigrams2 <- bigrams %>%
  count(party, bigrams, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(bigrams,party,n)

bigrams2 %>% 
    arrange(desc(tf_idf)) %>%
  mutate(word = factor(bigrams, levels = rev(unique(bigrams)))) %>% 
  group_by(party) %>% 
  top_n(10) 
  ungroup %>%
  ggplot(aes(bigrams, tf_idf, fill = party)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~party, ncol = 2, scales = "free") +
  coord_flip()
```


